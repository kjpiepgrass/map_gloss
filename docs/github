DOCUMENT:
dataset, choices notation and loading
vector loading
constants
path setting
model calling
model notation
inference model



## File Path Parsing Notation

### Purpose

Gloss mapping requires managing several languages from many datasets. File path parsing effectively replaces long portions of path that are likely to be the same by use of a lookup. This reduces the redundancy of hand creating many file path names within a dataset and allows all sharing the same path to be moved in the event of a change in directory location.

### Syntax

Any portion of a path contained in {{ }} will be treated as a variable to be parsed and replaced by the actual path. An example is below:
	ang,{{dev1}}/ang/testsuite-enriched.xml
The 3 characters before the comma in this case indicate that the ISO 639-3 code for the language is `ang`. The {{dev1}} in the path will be replaced by whatever is passed to the function.


### Example

Calling `load_datasets(data_path, var_paths={'dev1':'/home/user/aggregation/data})` would replace the {{dev1}} with /home/user/aggregation/data so that the full path becomes /home/user/aggregation/data/ang/testsuite-enriched.xml.

In map_gloss this occurs for loading datasets for training, testing, and deploying the model as well as in the inference procedure for loading choices files.


## Model Parsing Notation

### Purpose

Modeling several varying combinations of datasets and model methodologies may be important for some projects. Model parsing notation is a shorthand that informs the model about which datasets to use in training, testing, and cross-validation as well as which models to use and how to weight them if necessary.

### Syntax

Each line of the model must have 4 comma separated items. The first is the ID of the model which will be used to notate all outputs and reports from the model. The second is a notation for the datasets to be used for training. The third is either a notation for the datasets to be used for testing or they will have the value <cross> which will indicate to the model to perform leave-one-out-cross-validation. At this time <cross> has been deactivated until further development can occur. The fourth parameter is the model classifiers which contains all models to be used with their perspective weights.

Both the dataset strings and the model classifier strings are delimited with the & symbol. If multiple datasets or classifiers are used they must be delimited with &.

Datasets have the addition notation marks of - and !. - delimits language ISO 639-3 codes after the name of the dataset. Proper notation is dataset-ISO-ISO-ISO. Simply leaving the dataset without any languages - delimited will cause all languages to load for the dataset. Including the languages will cause only those listed to be loaded. On the other hand, ! will cause the dataset to load all languages in the dataset except those following the !. The ! can only appear directly after the name of the dataset and precede any language ISO 639-3 codes.

Each classifier in the model classifier string must have a weight. The notation is to have the name of the classifier then the @ symbol with the weight following between 0.00 and 1.00. The script will check that the summation of the weights for the model clasifier string are equal to 1.00.

### Examples

(1) `0x1,dev1&dev2,test,tbl@1.0`
(2) `0x2,dev1&dev2&test,<cross>,tbl@1.0`
(3) `0x3,dev1!rus&dev2&test,dev1-rus,tbl@1.0`

In example (1) the model has an ID of 0x1, will load all languages in datasets dev1 and dev2 for training, will load all languages in test for testing, and it will use the TBL classifier only.
In example (2) the model has an ID of 0x1, will load all languages in datasets dev1, dev2, and test for leave-one-out-cross-validation, and it will use the TBL classifier only.
In example (3) the model has an ID of 0x1, will load all languages in datasets dev1, dev2, and test except dev1's rus (Russian) for training, will load dev1's rus (Russian) for testing, and it will use the TBL classifier only.

Note that these examples use the main classifier that has proven effective for map gloss. Other classifiers are available though.
